# ğŸš€ OQS_step2 â€” API Flask Dockerizada (Ollama + OpenAI)

Uma API de Chat em Flask Dockerizada com suporte a Ollama (local, grÃ¡tis) e OpenAI API (remoto, pago). Projetada para rodar em qualquer ambiente e servir de base para integraÃ§Ãµes de IA em portfÃ³lio ou produÃ§Ã£o.

---

## âœ¨ Recursos
- API REST em Flask + Gunicorn
- Providers: Ollama (local, grÃ¡tis) e OpenAI (remoto, pago)
- Endpoints compatÃ­veis com OpenAI
- Streaming por linhas com heartbeats
- ConfiguraÃ§Ã£o via `.env`; pronto para Docker Compose

---

## ğŸ› ï¸ Quickstart

1) Copie o `.env` e ajuste conforme necessÃ¡rio
```
cp .env.example .env
```

2) Suba com Docker Compose (simples)
```
docker compose up -d --build
```
API: http://localhost:8000

Opcional (override de dev: mapeia UI estÃ¡tica e healthchecks)
```
docker compose -f docker-compose.yml -f docker-compose.override.yml up -d --build
```
API: http://localhost:9101

3) Health
```
curl http://localhost:8000/health   # ou :9101 se usar o override
```

---

## ğŸ” Trocar Provider (Ollama â†” OpenAI)

Por padrÃ£o, usamos Ollama (local, grÃ¡tis). Para usar OpenAI, no `.env` defina:
```
PROVIDER=openai
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
```
Rebuild/restart:
```
docker compose up -d --build
```

---

## ğŸ”Œ Endpoints
- GET `/health`: info do serviÃ§o + disponibilidade do Ollama (se habilitado)
- GET `/config`: modelo atual, ctx, predict
- GET `/models`: modelos do provider (tags do Ollama)
- POST `/chat`: body `{ message, stream? }` (suporta streaming)
- OpenAIâ€‘compatÃ­vel: `POST /v1/chat/completions`, `GET /v1/models`

Teste rÃ¡pido (Ollama padrÃ£o):
```
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "OlÃ¡ em 3 idiomas"}'
```
Com override, troque a porta para 9101.

Tester (roda `test_ai.py`):
```
docker compose run --rm tester
```

---

## ğŸ—‚ï¸ Estrutura
```
.
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py        # API Flask principal
â”‚  â”œâ”€ app/ollama_client.py# Cliente Ollama (lista/chat/stream)
â”‚  â”œâ”€ openai_proxy.py     # app auxiliar (chat simples OpenAI/Ollama)
â”‚  â””â”€ static/             # assets estÃ¡ticos da UI
â”œâ”€ templates/index.html   # UI simples de chat
â”œâ”€ test_ai.py             # teste rÃ¡pido
â”œâ”€ Dockerfile
â”œâ”€ docker-compose*.yml
â””â”€ .env(.example)
```

---

## ğŸ§¾ LicenÃ§a
MIT. Veja `LICENSE`.

