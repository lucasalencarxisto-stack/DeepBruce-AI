
---

## ğŸ‡¨ğŸ‡³ docs/README.zh.md
```markdown
# ğŸš€ OQS_step2 â€” DockeråŒ– Flask API (Ollama + OpenAI)

ä¸€ä¸ª **DockeråŒ–çš„ Flask èŠå¤© API**ï¼Œæ”¯æŒ **Ollamaï¼ˆæœ¬åœ°ï¼Œå…è´¹ï¼‰** å’Œ **OpenAI APIï¼ˆè¿œç¨‹ï¼Œä»˜è´¹ï¼‰**ã€‚  
æ—¨åœ¨åœ¨ä»»ä½•ç¯å¢ƒä¸­è¿è¡Œï¼Œå¹¶ä½œä¸º AI é›†æˆåˆ°ä½œå“é›†æˆ–ç”Ÿäº§é¡¹ç›®çš„åŸºç¡€ã€‚

---

## âœ¨ ç‰¹æ€§
- ğŸŒ åŸºäº **Flask** çš„ REST API
- ğŸ“¦ ä½¿ç”¨ **Docker + Compose** éƒ¨ç½²
- ğŸ”€ å¤šæä¾›è€…æ”¯æŒ:
  - **Ollama** â†’ æœ¬åœ°æ¨¡å‹ (`llama3.2:3b` ç­‰)
  - **OpenAI** â†’ GPT-4o, GPT-4o-mini ç­‰
- âš¡ ä¸ **OpenAI API** å…¼å®¹çš„ç«¯ç‚¹
- ğŸ›¡ï¸ é€šè¿‡ `.env` é…ç½®
- ğŸ” å†…ç½®å¥åº·æ£€æŸ¥å’ŒçŠ¶æ€

---

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/YOUR-USERNAME/oqs_step2.git
cd oqs_step2

2. åˆ›å»º .env
cp .env.example .env
ç¼–è¾‘é€‰æ‹© PROVIDER=ollamaï¼ˆé»˜è®¤ï¼‰æˆ– openai

3. ä½¿ç”¨ Docker Compose å¯åŠ¨
docker compose up -d --build

4. æµ‹è¯•å¥åº·çŠ¶æ€
curl http://localhost:8000/health

âš™ï¸ ä¸»è¦ç«¯ç‚¹
GET  /config
GET  /health
GET  /models
POST /chat               # { "message": "ä½ å¥½ï¼Œä¸–ç•Œï¼" }
POST /v1/chat/completions
GET  /v1/models

ğŸ§ª å¿«é€Ÿæµ‹è¯•
Ollama (é»˜è®¤)
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "ç”¨ä¸‰ç§è¯­è¨€æ‰“æ‹›å‘¼"}'

OpenAI (å¦‚æœæœ‰å¯†é’¥)
export PROVIDER=openai
export OPENAI_API_KEY=sk-xxxx

docker compose run --rm tester

ğŸ—‚ï¸ é¡¹ç›®ç»“æ„
.
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py       # Flask ä¸» API
â”‚  â”œâ”€ ollama_client.py  # Ollama å®¢æˆ·ç«¯
â”‚  â””â”€ static/           # å‰ç«¯ï¼ˆå¦‚æœæœ‰ï¼‰
â”œâ”€ test_ai.py           # æµ‹è¯•è„šæœ¬ (Ollama/OpenAI)
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ docker-compose.override.yml
â”œâ”€ .env.example
â”œâ”€ LICENSE
â””â”€ docs/
   â””â”€ LICENSE.md

ğŸ“– è®¸å¯è¯
æ ¹æ®  åˆ†å‘ã€‚
å¤šè¯­è¨€è¯´æ˜è§ ã€‚