# DeepBruce AI

DeepBruce AI is a prototype assistant with a simple, self-hosted API and a lightweight RAG pipeline that pulls fresh context directly from Wikipedia.  
The whole stack is Dockerized and can be lifted to any cloud (IaaS or PaaS) to support deeper Deep Learning / LLM development and experimentation.

## Highlights
- ğŸ”Œ Self-hosted API (Flask) with SSE streaming
- ğŸ§  Local inference via Ollama (model-agnostic)
- ğŸ“š Lightweight RAG: fetch + chunk + prompt-inject from Wikipedia
- ğŸ³ Fully containerized (Docker / Compose), cloud-ready
- âš™ï¸ Tunable prompts & hyper-params via `.env`
