# üß† Projeto OpenAI Quickstart (Flask + API)

Este projeto √© uma aplica√ß√£o web simples constru√≠da com Flask e a API da OpenAI. Permite aos usu√°rios enviar um prompt e receber uma resposta gerada pela IA.


<!-- Badges -->
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)](#)

---

## üìã Sum√°rio

- [Sobre](#sobre)  
- [Configura√ß√£o Inicial](#configura√ß√£o-inicial)  
- [Funcionalidades Atuais](#funcionalidades-atuais)  
- [Contribuindo](#contribuindo)  
- [Autor](#autor)  

---

## Sobre

Este projeto √© uma aplica√ß√£o web simples constru√≠da com Flask e a API da OpenAI. Permite que usu√°rios enviem prompts e recebam respostas geradas por IA.

---

## Contribuindo

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fa√ßa um fork do reposit√≥rio  
2. Crie sua branch de recurso (`git checkout -b minha-feature`)  
3. Fa√ßa commit das suas altera√ß√µes (`git commit -m 'Adicionar feature'`)  
4. Fa√ßa push para a branch (`git push origin minha-feature`)  
5. Abra um Pull Request  

Por favor, siga o estilo de c√≥digo existente e escreva mensagens de commit claras.

---

## üõ†Ô∏è Configura√ß√£o Inicial

Abaixo est√£o todos os passos que segui manualmente para configurar o ambiente. Isso demonstra dom√≠nio das ferramentas essenciais para desenvolvimento web e integra√ß√£o com IA.

1. Clone o reposit√≥rio

git clone https://github.com/your-username/openai-quickstart-01.git
cd openai-quickstart-01

2. Crie e ative o ambiente virtual  
Windows:  
python -m venv venv  
venv\Scripts\activate  

Linux/Mac:  
python3 -m venv venv  
source venv/bin/activate  

3. Instale as depend√™ncias  
pip install -r requirements.txt  

Se voc√™ n√£o tiver um arquivo requirements.txt, crie-o com:  
pip freeze > requirements.txt  

Certifique-se que ele contenha pelo menos:  
flask  
openai  
python-dotenv  

4. Configure a chave da API OpenAI  
Crie um arquivo .env com o seguinte conte√∫do:  
OPENAI_API_KEY=sua-chave-aqui  

Importante: use o .gitignore para nunca enviar sua chave ao GitHub.

5. Estrutura b√°sica esperada  
openai-quickstart-01/  
‚îú‚îÄ‚îÄ app.py  
‚îú‚îÄ‚îÄ .env  
‚îú‚îÄ‚îÄ requirements.txt  
‚îú‚îÄ‚îÄ README.md  
‚îú‚îÄ‚îÄ templates/  
‚îÇ   ‚îî‚îÄ‚îÄ index.html  
‚îú‚îÄ‚îÄ static/  
‚îÇ   ‚îî‚îÄ‚îÄ css/  
‚îÇ       ‚îî‚îÄ‚îÄ style.css  

6. Rode o app localmente  
flask run  

Abra seu navegador em: http://127.0.0.1:5000

---

## üìå Funcionalidades Atuais

- Interface web com formul√°rio para envio de prompt  
- Integra√ß√£o com API da OpenAI  
- Tratamento b√°sico de erros  
- Limite no tamanho da entrada do usu√°rio  
- Estilo CSS simples para o frontend  

---

Chatbot Flask com SSE e OpenAI
Este projeto √© uma aplica√ß√£o simples baseada no Flask, utilizando o modelo GPT da OpenAI. Ele suporta Server-Sent Events (SSE) para respostas em tempo real e gerenciamento de sess√µes.

Como Configurar o .env
1. Crie um arquivo .env no diret√≥rio raiz do projeto.
2. Adicione as seguintes vari√°veis no arquivo .env:
OPENAI_API_KEY=sua_chave_api_openai
OPENAI_MODEL=gpt-4o-mini
OPENAI_SUMMARY_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=800

Como Rodar Localmente
1. Instale as depend√™ncias:
pip install -r requirements.txt
2. Certifique-se de que o ambiente virtual esteja ativado:source venv/bin/activate  # No Linux/macOS
Rode o aplicativo Flask:
.\venv\Scripts\activate  # No Windows
source venv/bin/activate  # No Linux/macOS
3. Rode o aplicativo Flask:
python app.py
4. Acesse o aplicativo em http://127.0.0.1:5000/ no seu navegador.

Como Rodar em Produ√ß√£o
1. Defina debug=False em app.py.
2. Utilize um servidor WSGI como o gunicorn ou uvicorn:
gunicorn app:app

Principais Rotas e Funcionalidades
/status: Rota de verifica√ß√£o de sa√∫de que retorna {"status": "ok"}.

/: Interface principal de chat renderizada em HTML.

/chat: Rota POST que recebe uma mensagem do usu√°rio e a armazena no hist√≥rico da sess√£o.

/stream: Rota GET que transmite as respostas do chatbot em tempo real usando SSE.

/stream2: Rota POST que transmite as respostas do chatbot em tempo real usando um √∫nico endpoint.

Exemplos de Requisi√ß√µes
1. Verifica√ß√£o de Sa√∫de
curl http://127.0.0.1:5000/status
Resposta esperada:
{
  "status": "ok"
}
2. Enviar Mensagem para o Chat
curl -X POST http://127.0.0.1:5000/chat -H "Content-Type: application/json" -d '{"message": "Ol√°, chatbot!"}'
3. Resposta via Stream
curl http://127.0.0.1:5000/stream
4. Endpoint √önico de Stream
curl -X POST http://127.0.0.1:5000/stream2 -H "Content-Type: application/json" -d '{"message": "Me conte uma piada"}'

FAQ e Resolu√ß√£o de Problemas
P: Como configuro corretamente o arquivo .env?
R: Certifique-se de adicionar sua chave API da OpenAI e outras vari√°veis, como OPENAI_MODEL e OPENAI_TEMPERATURE, ao arquivo .env conforme mostrado acima.

P: Como posso rodar o Flask em produ√ß√£o?
R: Use um servidor WSGI como gunicorn para produ√ß√£o e defina debug=False em app.py.

Pr√≥ximos Passos:
Contribuindo: Se quiser contribuir, sinta-se √† vontade para fazer um fork e criar uma pull request!

Resolu√ß√£o de Problemas: Verifique a se√ß√£o de FAQ acima se encontrar algum problema.
---

## üë®‚Äçüíª Autor

Lucas Alencar  
Estudante de ADS, desenvolvedor iniciante mobile-first, apaixonado por Python, IA e tecnologias transformadoras.  
GitHub: https://github.com/lucasalencarxisto-stack
